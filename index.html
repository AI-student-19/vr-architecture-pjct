<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>VR Architecture Walkthrough with Voice Commands</title>
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
  </head>
  <body>
    <a-scene background="color: #a0a0a0">
      
      <!-- Lighting -->
      <a-entity light="type: ambient; color: #666; intensity: 0.5"></a-entity>
      <a-entity light="type: directional; color: #fff; intensity: 0.7" position="5 10 7"></a-entity>

      <!-- Ground -->
      <a-plane position="0 0 0" rotation="-90 0 0" width="100" height="100" color="#999"></a-plane>

      <!-- Camera rig -->
      <a-entity id="rig" position="0 1.6 0">
        <a-entity camera look-controls wasd-controls="acceleration: 10"></a-entity>
      </a-entity>

      <!-- GLB House -->
      <a-entity gltf-model="vr-house.glb" position="0 0 0" scale="1 1 1"></a-entity>

    </a-scene>

    <script>
      const roomPositions = {
        kitchen: {x: -0.7, y: -6.3, z:0},
        hall: {x:-0.8, y:-7.5, z: 0},
        bedroom1: {x: -0.85, y: -9.07, z: 0},
        bedroom2: {x: -0.72, y:-11, z: 0},
        bedroom3: {x: -12, y: 1.6, z: 2},
        sitting: {x: -0.4, y:-5.6, z: 0},
        lounge: {x:-0.6, y:-11.7, z: 0}
      };

      const rig = document.querySelector('#rig');

      // Voice Recognition
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.lang = 'en-US';

      recognition.onresult = function(event) {
        const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
        console.log("Heard:", transcript);

        for (let room in roomPositions) {
          if (transcript.includes(`go to ${room}`)) {
            rig.setAttribute('position', roomPositions[room]);
            console.log(`Teleporting to ${room}`);
          }
        }
      };

      recognition.start();
    </script>
  </body>
</html>
